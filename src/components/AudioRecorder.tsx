import { useState, useRef, useEffect, useCallback } from 'react';
import { useSearchParams, Link } from 'react-router-dom';
import { useAppStore } from '../store/useAppStore';
import { analyzeAudioWithGemini, RealtimeSpeechRecognizer, isGeminiAvailable } from '../lib/analyzeTranscript';
import { classifyError, formatErrorMessage, logError, handleSpeechRecognitionError } from '../lib/errorHandler';
import { createRecording, getProject, createAnalysis } from '../lib/database';
import type { Project, Recording } from '../types/project';

interface AudioRecorderProps {
  projectId?: string;
  project?: Project | null;
}

function AudioRecorder({ projectId: propProjectId, project: propProject }: AudioRecorderProps) {
  const [searchParams] = useSearchParams();
  const projectId = propProjectId || searchParams.get('projectId') || undefined;

  const [isRecording, setIsRecording] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [error, setError] = useState<string | null>(null);
  const [successMessage, setSuccessMessage] = useState<string | null>(null);
  
  // æ¡ˆä»¶é–¢é€£
  const [project, setProject] = useState<Project | null>(propProject || null);
  const [savedRecording, setSavedRecording] = useState<Recording | null>(null);
  const [isSaving, setIsSaving] = useState(false);
  
  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—é–¢é€£
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [realtimeTranscript, setRealtimeTranscript] = useState('');
  const [interimTranscript, setInterimTranscript] = useState('');

  // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰projectãŒæ¸¡ã•ã‚ŒãŸã‚‰æ›´æ–°
  useEffect(() => {
    if (propProject !== undefined) {
      setProject(propProject);
    }
  }, [propProject]);

  // ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã®ã¿æ¸¡ã•ã‚ŒãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆè¦ªã‹ã‚‰projectãŒæ¸¡ã•ã‚Œãªã„å ´åˆï¼‰
  useEffect(() => {
    if (projectId && !propProject) {
      getProject(projectId).then(projectData => {
        if (projectData) {
          setProject(projectData);
          // AudioRecorderã§ã¯ã‚¹ãƒˆã‚¢ã®æ›´æ–°ã‚’è¡Œã‚ãªã„ï¼ˆè¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ä»»ã›ã‚‹ï¼‰
        }
      });
    } else if (!projectId && !propProject) {
      setProject(null);
    }
  }, [projectId, propProject]);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const streamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const durationIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const recognizerRef = useRef<RealtimeSpeechRecognizer | null>(null);
  const fileInputRef = useRef<HTMLInputElement | null>(null);
  const [importedAudioBlob, setImportedAudioBlob] = useState<Blob | null>(null);
  const [importedAudioName, setImportedAudioName] = useState<string>('');
  const [importedAudioDuration, setImportedAudioDuration] = useState<number>(0);

  const {
    checklist,
    addMessage,
    setIsAnalyzing,
    isAnalyzing,
    setLastAnalysisResult,
  } = useAppStore();

  // Web Speech APIãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
  const isSpeechRecognitionAvailable = RealtimeSpeechRecognizer.isAvailable();

  // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
  const requestMicrophoneAccess = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });
      streamRef.current = stream;

      // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ¬ãƒ™ãƒ«ã‚’ç›£è¦–ã™ã‚‹ãŸã‚ã®AudioContextã‚’è¨­å®š
      const audioContext = new AudioContext();
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);

      analyser.fftSize = 256;
      source.connect(analyser);

      audioContextRef.current = audioContext;
      analyserRef.current = analyser;

      return stream;
    } catch (err) {
      const appError = classifyError(err);
      logError(appError, 'requestMicrophoneAccess');
      setError(formatErrorMessage(appError));
      throw err;
    }
  };

  // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ¬ãƒ™ãƒ«ã®ç›£è¦–
  const monitorAudioLevel = useCallback(() => {
    if (!analyserRef.current) return;

    const analyser = analyserRef.current;
    const dataArray = new Uint8Array(analyser.frequencyBinCount);

    const updateLevel = () => {
      if (!isRecording) return;

      analyser.getByteFrequencyData(dataArray);
      const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
      setAudioLevel(average);

      animationFrameRef.current = requestAnimationFrame(updateLevel);
    };

    updateLevel();
  }, [isRecording]);

  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹
  const startRealtimeTranscription = useCallback(() => {
    if (!isSpeechRecognitionAvailable) {
      console.log('Web Speech API is not available');
      return;
    }

    recognizerRef.current = new RealtimeSpeechRecognizer();
    recognizerRef.current.start(
      (text, isFinal) => {
        if (isFinal) {
          setRealtimeTranscript(text);
          setInterimTranscript('');
        } else {
          setInterimTranscript(text);
        }
      },
      (errorCode) => {
        const appError = handleSpeechRecognitionError(errorCode);
        logError(appError, 'speechRecognition');
        // éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼ã¯è»½å¾®ãªã®ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯é€šçŸ¥ã—ãªã„ï¼ˆãƒ­ã‚°ã®ã¿ï¼‰
      }
    );
    setIsTranscribing(true);
  }, [isSpeechRecognitionAvailable]);

  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’åœæ­¢
  const stopRealtimeTranscription = useCallback(() => {
    if (recognizerRef.current) {
      const finalTranscript = recognizerRef.current.stop();
      setRealtimeTranscript(finalTranscript);
      recognizerRef.current = null;
    }
    setIsTranscribing(false);
    setInterimTranscript('');
  }, []);

  // éŒ²éŸ³é–‹å§‹
  const startRecording = async () => {
    try {
      setError(null);
      const stream = await requestMicrophoneAccess();

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus',
      });

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.start(1000); // 1ç§’ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
      setIsRecording(true);
      setRecordingDuration(0);
      setRealtimeTranscript('');

      // éŒ²éŸ³æ™‚é–“ã®ã‚«ã‚¦ãƒ³ãƒˆ
      durationIntervalRef.current = setInterval(() => {
        setRecordingDuration((prev) => prev + 1);
      }, 1000);

      // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ¬ãƒ™ãƒ«ã®ç›£è¦–ã‚’é–‹å§‹
      monitorAudioLevel();

      // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹
      startRealtimeTranscription();
    } catch (err) {
      const appError = classifyError(err);
      setError(formatErrorMessage(appError));
      setIsRecording(false);
    }
  };

  // éŒ²éŸ³åœæ­¢
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);

      // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
        streamRef.current = null;
      }

      // AudioContextã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      if (audioContextRef.current) {
        audioContextRef.current.close();
        audioContextRef.current = null;
      }

      // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }

      // éŒ²éŸ³æ™‚é–“ã®ã‚«ã‚¦ãƒ³ãƒˆã‚’åœæ­¢
      if (durationIntervalRef.current) {
        clearInterval(durationIntervalRef.current);
        durationIntervalRef.current = null;
      }

      // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’åœæ­¢
      stopRealtimeTranscription();

      setAudioLevel(0);
    }
  };

  // éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’æ¡ˆä»¶ã«ä¿å­˜
  const saveRecordingToProject = async (recordingName?: string) => {
    if (!project || audioChunksRef.current.length === 0) {
      setError('ä¿å­˜ã™ã‚‹éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒãªã„ã‹ã€æ¡ˆä»¶ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
      return;
    }

    setIsSaving(true);
    setError(null);

    try {
      const audioBlob = new Blob(audioChunksRef.current, {
        type: 'audio/webm;codecs=opus',
      });

      const name = recordingName || `éŒ²éŸ³_${new Date().toLocaleString('ja-JP', {
        month: '2-digit',
        day: '2-digit',
        hour: '2-digit',
        minute: '2-digit',
      }).replace(/\//g, '-').replace(' ', '_')}`;

      const recording = await createRecording({
        projectId: project.id,
        name,
        audioBlob,
        mimeType: 'audio/webm;codecs=opus',
        duration: recordingDuration,
        source: 'realtime',
        transcript: realtimeTranscript || undefined,
      });

      setSavedRecording(recording);
      setSuccessMessage(`âœ… éŒ²éŸ³ã‚’ã€Œ${project.name}ã€ã«ä¿å­˜ã—ã¾ã—ãŸ`);
      
      // 3ç§’å¾Œã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¶ˆã™
      setTimeout(() => setSuccessMessage(null), 5000);
    } catch (err) {
      const appError = classifyError(err);
      logError(appError, 'saveRecordingToProject');
      setError(formatErrorMessage(appError));
    } finally {
      setIsSaving(false);
    }
  };

  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
  const handleFileImport = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    if (!file.type.startsWith('audio/')) {
      setError('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚');
      return;
    }

    try {
      setError(null);
      const audioBlob = new Blob([file], { type: file.type });
      
      // éŸ³å£°ã®é•·ã•ã‚’å–å¾—
      const audio = new Audio(URL.createObjectURL(audioBlob));
      await new Promise<void>((resolve, reject) => {
        audio.onloadedmetadata = () => {
          setImportedAudioDuration(Math.round(audio.duration));
          resolve();
        };
        audio.onerror = () => {
          console.warn('Failed to load audio metadata');
          setImportedAudioDuration(0);
          resolve();
        };
        audio.load();
      });

      setImportedAudioBlob(audioBlob);
      setImportedAudioName(file.name);
      setRealtimeTranscript(''); // ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã¯æ–‡å­—èµ·ã“ã—ãªã—
      
      // ãƒãƒ£ãƒƒãƒˆã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
      addMessage({
        role: 'user',
        content: `ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ\nãƒ•ã‚¡ã‚¤ãƒ«å: ${file.name}\nã‚µã‚¤ã‚º: ${(file.size / 1024).toFixed(1)}KB\né•·ã•: ${formatDuration(Math.round(audio.duration))}`,
      });
    } catch (err) {
      const appError = classifyError(err);
      logError(appError, 'handleFileImport');
      setError(formatErrorMessage(appError));
    } finally {
      // ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›ã®ãƒªã‚»ãƒƒãƒˆ
      if (fileInputRef.current) {
        fileInputRef.current.value = '';
      }
    }
  };

  // ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸéŸ³å£°ã‚’åˆ†æ
  const analyzeImportedAudio = async () => {
    if (!importedAudioBlob) {
      setError('ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚');
      return;
    }

    try {
      setIsAnalyzing(true);
      setError(null);

      addMessage({
        role: 'system',
        content: isGeminiAvailable()
          ? 'ğŸ” Gemini APIã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ã„ã¾ã™...'
          : 'ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã§åˆ†æã—ã¦ã„ã¾ã™...ï¼ˆãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼‰',
      });

      // ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸéŸ³å£°ã‚’åˆ†æï¼ˆæ–‡å­—èµ·ã“ã—ã¯ç©ºã€å¾Œã§å®Ÿè£…å¯èƒ½ï¼‰
      const analysisResult = await analyzeAudioWithGemini(
        importedAudioBlob,
        checklist,
        '' // ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã¯æ–‡å­—èµ·ã“ã—ãªã—
      );

      setLastAnalysisResult(analysisResult);

      addMessage({
        role: 'assistant',
        content: '',
        analysisResult,
      });

      // æ¡ˆä»¶ã«ä¿å­˜ã™ã‚‹å ´åˆã¯ã€ä¿å­˜å‡¦ç†ã‚’å®Ÿè¡Œ
      if (project) {
        await saveImportedRecordingToProject();
      }
    } catch (err) {
      const appError = classifyError(err);
      logError(appError, 'analyzeImportedAudio');
      setError(formatErrorMessage(appError));
      addMessage({
        role: 'system',
        content: `âŒ ã‚¨ãƒ©ãƒ¼: éŸ³å£°åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚`,
      });
    } finally {
      setIsAnalyzing(false);
    }
  };

  // ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸéŒ²éŸ³ã‚’æ¡ˆä»¶ã«ä¿å­˜
  const saveImportedRecordingToProject = async () => {
    if (!project || !importedAudioBlob) {
      setError('ä¿å­˜ã™ã‚‹éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒãªã„ã‹ã€æ¡ˆä»¶ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
      return;
    }

    setIsSaving(true);
    setError(null);

    try {
      const name = importedAudioName || `ã‚¤ãƒ³ãƒãƒ¼ãƒˆ_${new Date().toLocaleString('ja-JP', {
        month: '2-digit',
        day: '2-digit',
        hour: '2-digit',
        minute: '2-digit',
      }).replace(/\//g, '-').replace(' ', '_')}`;

      const recording = await createRecording({
        projectId: project.id,
        name,
        audioBlob: importedAudioBlob,
        mimeType: importedAudioBlob.type,
        duration: importedAudioDuration,
        source: 'import',
        transcript: undefined,
      });

      setSavedRecording(recording);
      setSuccessMessage(`âœ… éŒ²éŸ³ã‚’ã€Œ${project.name}ã€ã«ä¿å­˜ã—ã¾ã—ãŸ`);
      
      // ã‚¤ãƒ³ãƒãƒ¼ãƒˆçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
      setImportedAudioBlob(null);
      setImportedAudioName('');
      setImportedAudioDuration(0);
      
      // 3ç§’å¾Œã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¶ˆã™
      setTimeout(() => setSuccessMessage(null), 5000);
    } catch (err) {
      const appError = classifyError(err);
      logError(appError, 'saveImportedRecordingToProject');
      setError(formatErrorMessage(appError));
    } finally {
      setIsSaving(false);
    }
  };

  // è¦ç´„é–‹å§‹ï¼ˆç¾æ™‚ç‚¹ã¾ã§ã®éŸ³å£°ã‚’åˆ†æï¼‰
  const startAnalysis = async () => {
    if (audioChunksRef.current.length === 0) {
      setError('âŒ åˆ†æã™ã‚‹éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚éŒ²éŸ³ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚');
      return;
    }

    try {
      setIsAnalyzing(true);

      // ç¾æ™‚ç‚¹ã¾ã§ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
      const audioBlob = new Blob(audioChunksRef.current, {
        type: 'audio/webm;codecs=opus',
      });

      // ç¾åœ¨ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’å–å¾—
      const currentTranscript = recognizerRef.current?.getTranscript() || realtimeTranscript;

      // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
      addMessage({
        role: 'user',
        content: `ğŸ¤ è¦ç´„é–‹å§‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆ\nğŸ“ éŒ²éŸ³æ™‚é–“: ${formatDuration(recordingDuration)}\nğŸ’¾ éŸ³å£°ãƒ‡ãƒ¼ã‚¿: ${(audioBlob.size / 1024).toFixed(1)}KB\n${currentTranscript ? `ğŸ“– æ–‡å­—èµ·ã“ã—: ${currentTranscript.length}æ–‡å­—` : ''}`,
      });

      // ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
      addMessage({
        role: 'system',
        content: isGeminiAvailable() 
          ? 'ğŸ” Gemini APIã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ã„ã¾ã™...'
          : 'ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã§åˆ†æã—ã¦ã„ã¾ã™...ï¼ˆãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼‰',
      });

      // åˆ†æå®Ÿè¡Œ
      const result = await analyzeAudioWithGemini(audioBlob, checklist, currentTranscript);

      // çµæœã‚’ä¿å­˜
      setLastAnalysisResult(result);

      // åˆ†æçµæœã‚’ãƒãƒ£ãƒƒãƒˆã«è¿½åŠ 
      addMessage({
        role: 'assistant',
        content: '',
        analysisResult: result,
      });
    } catch (err) {
      const appError = classifyError(err);
      logError(appError, 'startAnalysis');
      setError(formatErrorMessage(appError));
      addMessage({
        role: 'system',
        content: `âŒ ã‚¨ãƒ©ãƒ¼: ${appError.message}`,
      });
    } finally {
      setIsAnalyzing(false);
    }
  };

  // æ™‚é–“ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
  const formatDuration = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (durationIntervalRef.current) {
        clearInterval(durationIntervalRef.current);
      }
      if (recognizerRef.current) {
        recognizerRef.current.stop();
      }
    };
  }, []);

  return (
    <div className="space-y-4">
      <div className="flex items-center justify-between">
        <h2 className="text-2xl font-semibold">ğŸ¤ éŸ³å£°éŒ²éŸ³</h2>
        <div className="flex items-center gap-2 text-sm">
          <span
            className={`px-2 py-1 rounded-full ${
              isGeminiAvailable()
                ? 'bg-green-100 text-green-700'
                : 'bg-yellow-100 text-yellow-700'
            }`}
          >
            {isGeminiAvailable() ? 'âœ… APIæ¥ç¶šæ¸ˆã¿' : 'âš ï¸ ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰'}
          </span>
          {isSpeechRecognitionAvailable && (
            <span className="px-2 py-1 rounded-full bg-blue-100 text-blue-700">
              ğŸ™ï¸ æ–‡å­—èµ·ã“ã—å¯¾å¿œ
            </span>
          )}
        </div>
      </div>

      {/* æ¡ˆä»¶é€£æºè¡¨ç¤º */}
      {project ? (
        <div className="bg-blue-50 border border-blue-200 rounded-lg p-3">
          <div className="flex items-center justify-between">
            <div>
              <span className="text-blue-600 text-sm font-medium">ğŸ“ æ¡ˆä»¶ã«ç´ä»˜ã‘ä¸­</span>
              <p className="font-semibold text-blue-800">{project.name}</p>
            </div>
            <Link
              to={`/projects/${project.id}`}
              className="text-blue-600 hover:underline text-sm"
            >
              æ¡ˆä»¶è©³ç´° â†’
            </Link>
          </div>
        </div>
      ) : (
        <div className="bg-gray-50 border border-gray-200 rounded-lg p-3">
          <div className="flex items-center justify-between">
            <div>
              <span className="text-gray-500 text-sm">ğŸ“ æ¡ˆä»¶æœªé¸æŠ</span>
              <p className="text-gray-600 text-sm">éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚çš„ã«ä¿æŒã•ã‚Œã¾ã™</p>
            </div>
            <Link
              to="/projects"
              className="text-blue-600 hover:underline text-sm"
            >
              æ¡ˆä»¶ã‚’é¸æŠ â†’
            </Link>
          </div>
        </div>
      )}

      {/* æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */}
      {successMessage && (
        <div className="bg-green-50 border border-green-200 text-green-700 px-4 py-3 rounded flex items-center justify-between">
          <span>{successMessage}</span>
          {savedRecording && project && (
            <Link
              to={`/projects/${project.id}`}
              className="text-green-800 hover:underline font-medium"
            >
              æ¡ˆä»¶ã‚’é–‹ã â†’
            </Link>
          )}
        </div>
      )}

      {error && (
        <div className="bg-red-50 border border-red-200 text-red-700 px-4 py-3 rounded whitespace-pre-wrap">
          {error}
        </div>
      )}

      {/* éŒ²éŸ³æ™‚é–“è¡¨ç¤º */}
      {isRecording && (
        <div className="text-center py-4">
          <div className="text-4xl font-mono font-bold text-gray-800">
            {formatDuration(recordingDuration)}
          </div>
          <div className="text-sm text-gray-500 mt-1">éŒ²éŸ³æ™‚é–“</div>
        </div>
      )}

      {/* ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸéŸ³å£°ã®æƒ…å ± */}
      {importedAudioBlob && !isRecording && (
        <div className="bg-blue-50 border border-blue-200 rounded-lg p-4 mb-4">
          <div className="flex items-center justify-between mb-2">
            <h3 className="font-semibold text-blue-800">ğŸ“ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸéŸ³å£°</h3>
            <button
              onClick={() => {
                setImportedAudioBlob(null);
                setImportedAudioName('');
                setImportedAudioDuration(0);
              }}
              className="text-blue-600 hover:text-blue-800 text-sm"
            >
              âœ• ã‚¯ãƒªã‚¢
            </button>
          </div>
          <div className="text-sm text-blue-700 space-y-1">
            <p>ãƒ•ã‚¡ã‚¤ãƒ«å: {importedAudioName}</p>
            <p>é•·ã•: {formatDuration(importedAudioDuration)}</p>
            <p>ã‚µã‚¤ã‚º: {(importedAudioBlob.size / 1024).toFixed(1)} KB</p>
          </div>
          {/* éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ */}
          <div className="mt-3">
            <audio
              controls
              className="w-full"
              src={URL.createObjectURL(importedAudioBlob)}
            />
          </div>
        </div>
      )}

      {/* ãƒœã‚¿ãƒ³ */}
      <div className="flex items-center gap-3 flex-wrap">
        <button
          onClick={isRecording ? stopRecording : startRecording}
          className={`px-6 py-3 rounded-lg font-semibold transition-colors ${
            isRecording
              ? 'bg-red-500 hover:bg-red-600 text-white'
              : 'bg-blue-500 hover:bg-blue-600 text-white'
          }`}
        >
          {isRecording ? 'â¹ éŒ²éŸ³åœæ­¢' : 'ğŸ¤ éŒ²éŸ³é–‹å§‹'}
        </button>

        {/* éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ */}
        <div>
          <input
            ref={fileInputRef}
            type="file"
            accept="audio/*"
            onChange={handleFileImport}
            className="hidden"
            id="audio-import"
          />
          <label
            htmlFor="audio-import"
            className="px-6 py-3 rounded-lg font-semibold transition-colors bg-gray-500 hover:bg-gray-600 text-white cursor-pointer inline-block"
          >
            ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
          </label>
        </div>

        {importedAudioBlob ? (
          <button
            onClick={analyzeImportedAudio}
            disabled={isAnalyzing}
            className={`px-6 py-3 rounded-lg font-semibold transition-colors ${
              !isAnalyzing
                ? 'bg-green-500 hover:bg-green-600 text-white'
                : 'bg-gray-300 text-gray-500 cursor-not-allowed'
            }`}
          >
            {isAnalyzing ? 'â³ åˆ†æä¸­...' : 'ğŸ“Š ã‚¤ãƒ³ãƒãƒ¼ãƒˆéŸ³å£°ã‚’åˆ†æ'}
          </button>
        ) : (
          <button
            onClick={startAnalysis}
            disabled={!isRecording || isAnalyzing}
            className={`px-6 py-3 rounded-lg font-semibold transition-colors ${
              isRecording && !isAnalyzing
                ? 'bg-green-500 hover:bg-green-600 text-white'
                : 'bg-gray-300 text-gray-500 cursor-not-allowed'
            }`}
          >
            {isAnalyzing ? 'â³ åˆ†æä¸­...' : 'ğŸ“Š è¦ç´„é–‹å§‹'}
          </button>
        )}

        {/* æ¡ˆä»¶ã«ä¿å­˜ãƒœã‚¿ãƒ³ï¼ˆæ¡ˆä»¶é¸æŠæ™‚ã®ã¿ã€éŒ²éŸ³åœæ­¢å¾Œã«è¡¨ç¤ºï¼‰ */}
        {project && !isRecording && audioChunksRef.current.length > 0 && !savedRecording && (
          <button
            onClick={() => saveRecordingToProject()}
            disabled={isSaving}
            className={`px-6 py-3 rounded-lg font-semibold transition-colors ${
              isSaving
                ? 'bg-gray-300 text-gray-500 cursor-not-allowed'
                : 'bg-purple-500 hover:bg-purple-600 text-white'
            }`}
          >
            {isSaving ? 'â³ ä¿å­˜ä¸­...' : 'ğŸ’¾ æ¡ˆä»¶ã«ä¿å­˜'}
          </button>
        )}

        {isRecording && (
          <div className="flex items-center gap-2">
            <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse"></div>
            <span className="text-sm text-gray-600">éŒ²éŸ³ä¸­...</span>
          </div>
        )}
      </div>

      {/* ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ¬ãƒ™ãƒ«è¡¨ç¤º */}
      {isRecording && (
        <div className="mt-4">
          <div className="flex items-center gap-2 mb-2">
            <span className="text-sm text-gray-600">éŸ³å£°ãƒ¬ãƒ™ãƒ«:</span>
            <div className="flex-1 bg-gray-200 rounded-full h-3 overflow-hidden">
              <div
                className={`h-full transition-all duration-100 ${
                  audioLevel > 50
                    ? 'bg-green-500'
                    : audioLevel > 20
                    ? 'bg-yellow-500'
                    : 'bg-gray-400'
                }`}
                style={{ width: `${Math.min(audioLevel * 2, 100)}%` }}
              ></div>
            </div>
          </div>
        </div>
      )}

      {/* ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—è¡¨ç¤º */}
      {isRecording && isSpeechRecognitionAvailable && (
        <div className="mt-4 p-4 bg-blue-50 rounded-lg border border-blue-200">
          <div className="flex items-center gap-2 mb-2">
            <h3 className="font-semibold text-blue-800">ğŸ“ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—</h3>
            {isTranscribing && (
              <div className="w-2 h-2 bg-blue-500 rounded-full animate-pulse"></div>
            )}
          </div>
          <div className="text-gray-700 min-h-[60px] max-h-[150px] overflow-y-auto">
            {realtimeTranscript || interimTranscript ? (
              <>
                <span>{realtimeTranscript}</span>
                <span className="text-gray-400 italic">{interimTranscript}</span>
              </>
            ) : (
              <span className="text-gray-400">è©±ã—å§‹ã‚ã‚‹ã¨æ–‡å­—èµ·ã“ã—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™...</span>
            )}
          </div>
        </div>
      )}

      {/* ä½¿ã„æ–¹ */}
      <div className="mt-4 p-4 bg-gray-50 rounded-lg">
        <h3 className="font-semibold mb-2">ğŸ“ ä½¿ã„æ–¹</h3>
        <ol className="text-sm text-gray-600 space-y-1 list-decimal list-inside">
          <li>ã€ŒğŸ¤ éŒ²éŸ³é–‹å§‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦éŒ²éŸ³ã‚’é–‹å§‹</li>
          <li>ä¼šè­°ä¸­ã€ä»»æ„ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã€ŒğŸ“Š è¦ç´„é–‹å§‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯</li>
          <li>ãã®æ™‚ç‚¹ã¾ã§ã®ä¼šè©±å†…å®¹ãŒãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã¨çªåˆã•ã‚Œã¾ã™</li>
          <li>å³å´ã®ãƒãƒ£ãƒƒãƒˆãƒ‘ãƒãƒ«ã«åˆ†æçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™</li>
        </ol>
      </div>
    </div>
  );
}

export default AudioRecorder;
